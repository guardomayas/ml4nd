{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkInOPFnzoQK"
      },
      "source": [
        "# Generalized Linear Models\n",
        "\n",
        "In this lab, you'll build generalized linear models (GLMs) and convolutional neural network (CNN) models of retinal ganglion cell (RGC) responses to visual stimuli. You'll use PyTorch to implement the models and fit them to a dataset  kindly provided by the [Baccus Lab](https://baccuslab.stanford.edu/) (Stanford University), which they studied in the \"Deep Retina\" paper [(McIntosh et al, 2016)](https://arxiv.org/abs/1702.01825).\n",
        "\n",
        "**References:**\n",
        "\n",
        "McIntosh, Lane T., Niru Maheswaranathan, Aran Nayebi, Surya Ganguli, and Stephen A. Baccus. “Deep Learning Models of the Retinal Response to Natural Scenes.” Advances in Neural Information Processing (NeurIPS), 2017."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GKupsmKxxvx"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY1dqa8CgQqi",
        "outputId": "a1b673a0-42d4-4070-8395-7d2235b2c117"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import jaxtyping\n",
        "except:\n",
        "    !pip install jaxtyping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn6yXI4rXhof"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from copy import deepcopy\n",
        "from typing import Tuple, Dict, Optional\n",
        "from jaxtyping import Float\n",
        "from torch import Tensor\n",
        "from torch.distributions import Poisson\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.auto import trange\n",
        "\n",
        "# Specify that we want our tensors on the GPU and in float32\n",
        "device = torch.device('cuda')\n",
        "dtype = torch.float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjI6pKa0gQqj"
      },
      "source": [
        "### Helper functions for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "X0H23MgeD03y",
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "#@title Helper functions for plotting (run this cell!)\n",
        "sns.set_context(\"notebook\")\n",
        "\n",
        "# initialize a color palette for plotting\n",
        "palette = sns.xkcd_palette([\"windows blue\",\n",
        "                            \"red\",\n",
        "                            \"medium green\",\n",
        "                            \"dusty purple\",\n",
        "                            \"orange\",\n",
        "                            \"amber\",\n",
        "                            \"clay\",\n",
        "                            \"pink\",\n",
        "                            \"greyish\"])\n",
        "\n",
        "def plot_stimulus_weights(glm: nn.Module):\n",
        "    \"\"\"\n",
        "    Plot the stimulus weights of a GLM.\n",
        "    \"\"\"\n",
        "    num_neurons = glm.num_neurons\n",
        "    max_delay = glm.max_delay\n",
        "\n",
        "    fig, axs = plt.subplots(num_neurons, 3, figsize=(8, 4 * num_neurons),\n",
        "                            gridspec_kw=dict(width_ratios=[1, 1.9, .1]))\n",
        "\n",
        "    temporal_weights = glm.temporal_conv.weight[:, 0].to(\"cpu\").detach()\n",
        "    bias = glm.temporal_conv.bias.to(\"cpu\").detach()\n",
        "    spatial_weights = glm.spatial_conv.weight.to(\"cpu\").detach()\n",
        "    spatial_weights = spatial_weights.reshape(num_neurons, 50, 50)\n",
        "\n",
        "    # normalize and flip the spatial weights\n",
        "    for n in range(num_neurons):\n",
        "        # Flip if spatial weight peak is negative\n",
        "        if torch.allclose(spatial_weights[n].min(),\n",
        "                       -abs(spatial_weights[n]).max()):\n",
        "            spatial_weights[n] = -spatial_weights[n]\n",
        "            temporal_weights[n] = -temporal_weights[n]\n",
        "\n",
        "        # Normalize\n",
        "        scale = torch.linalg.norm(spatial_weights[n])\n",
        "        spatial_weights[n] /= scale\n",
        "        temporal_weights[n] *= scale\n",
        "\n",
        "    # Set the same limits for each neuron\n",
        "    vlim = abs(spatial_weights).max()\n",
        "    ylim = abs(temporal_weights).max()\n",
        "\n",
        "    for n in range(num_neurons):\n",
        "        axs[n, 0].plot(torch.arange(-max_delay+1, 1) * 10, temporal_weights[n])\n",
        "        axs[n, 0].set_ylim(-ylim, ylim)\n",
        "        axs[n, 0].plot(torch.arange(-max_delay+1, 1) * 10, torch.zeros(max_delay), ':k')\n",
        "        if n < num_neurons - 1:\n",
        "            axs[n, 0].set_xticklabels([])\n",
        "        else:\n",
        "            axs[n, 0].set_xlabel(\"$\\Delta t$ [ms]\")\n",
        "\n",
        "        im = axs[n, 1].imshow(spatial_weights[n],\n",
        "                              vmin=-vlim, vmax=vlim, cmap=\"RdBu\")\n",
        "        axs[n, 1].set_axis_off()\n",
        "        axs[n, 1].set_title(\"neuron {}\".format(n + 1))\n",
        "        plt.colorbar(im, cax=axs[n, 2])\n",
        "\n",
        "\n",
        "def plot_coupling_weights(glm: nn.Module):\n",
        "    \"\"\"\n",
        "    Plot the coupling weights of a GLM.\n",
        "    \"\"\"\n",
        "    # Get the weights and flip them to get time after spike\n",
        "    W = glm.coupling_conv.weight.to(\"cpu\").detach()\n",
        "    W = torch.flip(W, dims=(2,))\n",
        "    num_neurons = W.shape[0]\n",
        "    wlim = abs(W).max()\n",
        "    dt = 10 * torch.arange(W.shape[2])\n",
        "\n",
        "    fig, axs = plt.subplots(num_neurons, num_neurons, figsize=(12, 12),\n",
        "                            sharex=True, sharey=True)\n",
        "    for i in range(num_neurons):\n",
        "        for j in range(num_neurons):\n",
        "            axs[i, j].plot(dt, 0 * dt, ':k')\n",
        "            axs[i, j].plot(dt, W[i, j])\n",
        "            axs[i, j].set_ylim(-wlim, wlim)\n",
        "            axs[i, j].set_title(\"${} \\\\to {}$\".format(j, i))\n",
        "\n",
        "            if i == num_neurons - 1:\n",
        "                axs[i, j].set_xlabel(\"$\\Delta t$ [ms]\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "def plot_cnn_subunits_1(cnn: nn.Module):\n",
        "    \"\"\"\n",
        "    Plot the first layer of subunits of a CNN.\n",
        "    \"\"\"\n",
        "    num_subunits = cnn.num_subunits_1\n",
        "    max_delay = cnn.max_delay\n",
        "\n",
        "    fig, axs = plt.subplots(num_subunits, 3, figsize=(8, 4 * num_subunits),\n",
        "                            gridspec_kw=dict(width_ratios=[1, 1.9, .1]))\n",
        "\n",
        "    temporal_weights = cnn.temporal_conv.weight[:, 0].to(\"cpu\").detach()\n",
        "    bias = cnn.temporal_conv.bias.to(\"cpu\").detach()\n",
        "    spatial_weights = cnn.spatial_conv.weight.to(\"cpu\").detach()\n",
        "    spatial_weights = spatial_weights[:, 0, :, :]\n",
        "\n",
        "    # normalize and flip the spatial weights\n",
        "    for n in range(num_subunits):\n",
        "        # Flip if spatial weight peak is negative\n",
        "        if torch.allclose(spatial_weights[n].min(),\n",
        "                    -abs(spatial_weights[n]).max()):\n",
        "            spatial_weights[n] = -spatial_weights[n]\n",
        "            temporal_weights[n] = -temporal_weights[n]\n",
        "\n",
        "        # Normalize\n",
        "        scale = torch.linalg.norm(spatial_weights[n])\n",
        "        spatial_weights[n] /= scale\n",
        "        temporal_weights[n] *= scale\n",
        "\n",
        "    # Set the same limits for each neuron\n",
        "    vlim = abs(spatial_weights).max()\n",
        "    ylim = abs(temporal_weights).max()\n",
        "\n",
        "    for n in range(num_subunits):\n",
        "        axs[n, 0].plot(torch.arange(-max_delay+1, 1) * 10, temporal_weights[n])\n",
        "        axs[n, 0].set_ylim(-ylim, ylim)\n",
        "        axs[n, 0].plot(torch.arange(-max_delay+1, 1) * 10, torch.zeros(max_delay), ':k')\n",
        "        if n < num_subunits - 1:\n",
        "            axs[n, 0].set_xticklabels([])\n",
        "        else:\n",
        "            axs[n, 0].set_xlabel(\"$\\Delta t$ [ms]\")\n",
        "\n",
        "        im = axs[n, 1].imshow(spatial_weights[n],\n",
        "                              vmin=-vlim, vmax=vlim, cmap=\"RdBu\")\n",
        "        axs[n, 1].set_axis_off()\n",
        "        axs[n, 1].set_title(\"subunit 1,{}\".format(n + 1))\n",
        "        plt.colorbar(im, cax=axs[n, 2])\n",
        "\n",
        "def plot_cnn_subunits2(cnn: nn.Module):\n",
        "    \"\"\"\n",
        "    Plot the second layer of subunits of a CNN.\n",
        "    \"\"\"\n",
        "    cnn_filters_2 = cnn.layer2.weight.to(\"cpu\").detach()\n",
        "\n",
        "    fig, axs = plt.subplots(cnn.num_subunits_2,\n",
        "                            cnn.num_subunits_1,\n",
        "                            figsize=(4 * cnn.num_subunits_2,\n",
        "                                    4 * cnn.num_subunits_1),\n",
        "                            sharex=True, sharey=True)\n",
        "    vlim = abs(cnn_filters_2).max()\n",
        "    for i in range(cnn.num_subunits_2):\n",
        "        for j in range(cnn.num_subunits_1):\n",
        "            axs[i, j].imshow(cnn_filters_2[i, j],\n",
        "                            vmin=-vlim, vmax=vlim, cmap=\"RdBu\")\n",
        "\n",
        "            axs[i, j].set_title('subunit 1,{} $\\\\to$ 2,{}'.format(j+1,i+1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXtkdF0DgQqj"
      },
      "source": [
        "### Helper function to train a Pytorch model.\n",
        "\n",
        "We've slightly modified the `train_model` function from the previous lab. This version keeps track of the model with the best validation loss over the course of the training epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "z9HtrRrE4ox9",
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "#@title Implement `train_model` function (run this cell!)\n",
        "def train_model(model: nn.Module,\n",
        "                train_dataset: Dataset,\n",
        "                val_dataset: Dataset,\n",
        "                objective: callable,\n",
        "                regularizer: Optional[callable]=None,\n",
        "                num_epochs: int=100,\n",
        "                lr: float=0.1,\n",
        "                momentum: float=0.9,\n",
        "                lr_step_size: int=25,\n",
        "                lr_gamma: float=0.9\n",
        "                ) -> Tuple[Float[Tensor, \" num_epochs\"],\n",
        "                           Float[Tensor, \" num_epochs\"]]:\n",
        "    \"\"\"\n",
        "    Train a model on the training dataset and validate it on the validation\n",
        "    dataset. The model is trained using stochastic gradient descent with a\n",
        "    decaying learning rate. The model is trained for `num_epochs` epochs and\n",
        "    the learning rate is decayed every `lr_step_size` epochs by a factor of\n",
        "    `lr_gamma`. The model is trained using the specified `objective` function\n",
        "    and an optional `regularizer`.\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : nn.Module\n",
        "        The model to be trained.\n",
        "    train_dataset : Dataset\n",
        "        The training dataset.\n",
        "    val_dataset : Dataset\n",
        "        The validation dataset.\n",
        "    objective : callable\n",
        "        The objective function to be minimized.\n",
        "    regularizer : callable, optional\n",
        "        The regularizer to be added to the objective function. The default\n",
        "        is None.\n",
        "    num_epochs : int, optional\n",
        "        The number of epochs to train the model. The default is 100.\n",
        "    lr : float, optional\n",
        "        The learning rate for the optimizer. The default is 0.1.\n",
        "    momentum : float, optional\n",
        "        The momentum for the optimizer. The default is 0.9.\n",
        "    lr_step_size : int, optional\n",
        "        The number of epochs after which to decay the learning rate. The\n",
        "        default is 25.\n",
        "    lr_gamma : float, optional\n",
        "        The factor by which to decay the learning rate. The default is 0.9.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple[Float[Tensor, \" num_epochs\"], Float[Tensor, \" num_epochs\"]]\n",
        "        The training and validation losses for each epoch.\n",
        "    \"\"\"\n",
        "    # progress bars\n",
        "    pbar = trange(num_epochs)\n",
        "    pbar.set_description(\"---\")\n",
        "    inner_pbar = trange(len(train_dataset))\n",
        "    inner_pbar.set_description(\"Batch\")\n",
        "\n",
        "    # data loaders for train and validation\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=1)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=1)\n",
        "    dataloaders = dict(train=train_dataloader, val=val_dataloader)\n",
        "\n",
        "    # use standard SGD with a decaying learning rate\n",
        "    optimizer = optim.SGD(model.parameters(),\n",
        "                          lr=lr,\n",
        "                          momentum=momentum)\n",
        "    scheduler = lr_scheduler.StepLR(optimizer,\n",
        "                                    step_size=lr_step_size,\n",
        "                                    gamma=lr_gamma)\n",
        "\n",
        "    # Keep track of the best model\n",
        "    best_model_wts = deepcopy(model.state_dict())\n",
        "    best_loss = 1e8\n",
        "\n",
        "    # Track the train and validation loss\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'val']:\n",
        "            # set model to train/validation as appropriate\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "                inner_pbar.reset()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            # track the running loss over batches\n",
        "            running_loss = 0\n",
        "            running_size = 0\n",
        "            for datapoint in dataloaders[phase]:\n",
        "                stim_t = datapoint['stimulus'].squeeze(0)\n",
        "                spikes_t = datapoint['spikes'].squeeze(0)\n",
        "                if phase == \"train\":\n",
        "                    with torch.set_grad_enabled(True):\n",
        "                        optimizer.zero_grad()\n",
        "                        # compute the model output and loss\n",
        "                        output_t = model(stim_t, spikes_t)\n",
        "                        loss_t = objective(output_t, spikes_t)\n",
        "                        # only add the regularizer in the training phase\n",
        "                        if regularizer is not None:\n",
        "                            loss_t += regularizer(model)\n",
        "\n",
        "                        # take the gradient and perform an sgd step\n",
        "                        loss_t.backward()\n",
        "                        optimizer.step()\n",
        "                    inner_pbar.update(1)\n",
        "                else:\n",
        "                    # just compute the loss in validation\n",
        "                    output_t = model(stim_t, spikes_t)\n",
        "                    loss_t = objective(output_t, spikes_t)\n",
        "\n",
        "                assert torch.isfinite(loss_t)\n",
        "                running_loss += loss_t.item()\n",
        "                running_size += 1\n",
        "\n",
        "            # compute the train/validation loss and update the best\n",
        "            # model parameters if this is the lowest validation loss yet\n",
        "            running_loss /= running_size\n",
        "            if phase == \"train\":\n",
        "                train_losses.append(running_loss)\n",
        "            else:\n",
        "                val_losses.append(running_loss)\n",
        "                if running_loss < best_loss:\n",
        "                    best_loss = running_loss\n",
        "                    best_model_wts = deepcopy(model.state_dict())\n",
        "\n",
        "        # Update the learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Update the progress bar\n",
        "        pbar.set_description(\"Epoch {:03} Train {:.4f} Val {:.4f}\"\\\n",
        "                             .format(epoch, train_losses[-1], val_losses[-1]))\n",
        "        pbar.update(1)\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return torch.tensor(train_losses), torch.tensor(val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdRq6bR4h5Sz"
      },
      "source": [
        "### Load the data\n",
        "\n",
        "Load the data from the HDF5 file.\n",
        "- Each file contains a `train` and `test` group.\n",
        "- Each group contains:\n",
        "    - `time`: length `frames` array of timestamps\n",
        "    - `stimulus`: a `frames x 50 x 50` video taken at ~100Hz\n",
        "    - `response`: a group with\n",
        "        - `binned`: `cells x frames` array of spike counts (for the training data) or rates (for the test data) in each bin\n",
        "        - `firing_rate_xms` where `x` is 5, 10, or 20 milliseconds\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vn8xa-Md9oG",
        "outputId": "a2af8b0d-8135-46cd-ced3-8f9ed2235df6"
      },
      "outputs": [],
      "source": [
        "!wget -nc https://github.com/slinderman/ml4nd/raw/refs/heads/main/data/04_glms/lab4_data.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BK5GG1_2eLsZ"
      },
      "outputs": [],
      "source": [
        "# Load the white noise data\n",
        "f = h5py.File(\"lab4_data.h5\", mode='r')\n",
        "times = torch.tensor(f['train']['time'][:], dtype=dtype)\n",
        "stimulus = torch.tensor(f['train']['stimulus'][:], dtype=torch.uint8)\n",
        "spikes = torch.tensor(f['train']['response']['binned'][:].T, dtype=dtype)\n",
        "test_times = torch.tensor(f['test']['time'][:], dtype=dtype)\n",
        "test_stimulus = torch.tensor(f['test']['stimulus'][:], dtype=torch.uint8)\n",
        "test_rates = torch.tensor(f['test']['response']['binned'][:, :-1].T, dtype=dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AntU2cN4gQql"
      },
      "outputs": [],
      "source": [
        "# Extract/set some constants.\n",
        "NUM_FRAMES, HEIGHT, WIDTH = stimulus.shape\n",
        "_, NUM_NEURONS = spikes.shape\n",
        "FRAME_RATE = 100    # Hz\n",
        "MAX_DELAY = 40      # frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h83mfn1O8dOy"
      },
      "source": [
        "## Part 1: Plot the data\n",
        "\n",
        "Always visualize your data first!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcszNvfvQw3m"
      },
      "source": [
        "### Problem 1a: Plot a slice of the spike train\n",
        "\n",
        "Write a function to `imshow` a slice of the data.\n",
        "Add a colorbar and label your axes!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "y7KHHJrysLwI",
        "outputId": "eeb1952d-3104-45fc-da27-3e11579e69a9"
      },
      "outputs": [],
      "source": [
        "# Plot a few seconds of the spike train\n",
        "def plot_spike_train(spikes: Float[Tensor, \"num_frames num_neurons\"],\n",
        "                     t_start: float,\n",
        "                     t_stop: float,\n",
        "                     figsize: Tuple[int, int]=(12, 6)\n",
        "                     ) -> None:\n",
        "    \"\"\"\n",
        "    Visualize a window of the spike count matrix.\n",
        "\n",
        "    spikes:  time x neuron spike count matrix\n",
        "    t_start: time (in seconds) of the start of the window\n",
        "    t_stop:  time (in seconds) of the end of the window\n",
        "    figsize: width and height of the figure in inches\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    ###\n",
        "    # YOUR CODE BELOW\n",
        "    ...\n",
        "    ###\n",
        "\n",
        "plot_spike_train(spikes, 0, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgEAmHRB0JfA"
      },
      "source": [
        "### Problem 1b: Compute the baseline firing rate for each neuron\n",
        "\n",
        "Print the mean firing rate for each neuron (on the training data) in spikes per second."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_N1KmLQ1Eaj",
        "outputId": "507d4dba-0f09-4e64-9832-db0a062db6b9"
      },
      "outputs": [],
      "source": [
        "###\n",
        "# Compute the firing rates\n",
        "# YOUR CODE BELOW\n",
        "...\n",
        "###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFdCd4yoQt1Y"
      },
      "source": [
        "### Plot a few frames of the stimulus\n",
        "\n",
        "Plot the 0th, 10th, 20th, and 30th frames of stimulus in grayscale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "LGYNySW4sJPl",
        "outputId": "55bb3dfc-5fcf-4d0e-df1a-4af27e74b4db"
      },
      "outputs": [],
      "source": [
        "# Plot a few frames of stimulus\n",
        "def plot_stimulus(stimulus, frame_inds, n_cols=4, panel_size=4):\n",
        "    num_frames = len(frame_inds)\n",
        "    n_rows = int(torch.ceil(torch.tensor(num_frames / n_cols)))\n",
        "    fig, axs = plt.subplots(\n",
        "        n_rows, n_cols, figsize=(n_cols * panel_size, n_rows * panel_size))\n",
        "    for ax, ind in zip(axs.ravel(), frame_inds):\n",
        "        ax.imshow(stimulus[ind], cmap=\"Greys\")\n",
        "        ax.set_title(\"Stimulus Frame {}\".format(ind))\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    for ax in axs.ravel()[len(frame_inds):]:\n",
        "        ax.set_visible(False)\n",
        "\n",
        "plot_stimulus(stimulus, [0, 10, 20, 30])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTjRhwb8Q83L"
      },
      "source": [
        "### Problem 1c: Compute and plot the spike triggered average\n",
        "\n",
        "The spike triggered average for neuron $n$ is the average stimulus in the lead-up to a spike by that neuron.\n",
        "\n",
        "Formally, let $A_n \\in \\mathbb{R}^{D \\times P_H \\times P_W}$ denote the STA for neuron $n$. It's defined as,\n",
        "\\begin{align}\n",
        "A_{n,d,i,j} = \\frac{1}{S_{n,d}} \\sum_{t=d+1}^T x_{t-d,i,j} \\mathbb{I}[y_{t,n} >0]\n",
        "\\end{align}\n",
        "where $S_{n,d} = \\sum_{t=d+1}^T \\mathbb{I}[y_{t,n} >0]$ is the number of spikes on neuron $n$, accounting for edge effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "6fdmKcetfh8D",
        "outputId": "d8954055-9931-44a7-aa52-fea72acb514d"
      },
      "outputs": [],
      "source": [
        "def compute_sta(neuron: int,\n",
        "                stimulus: Float[Tensor, \"num_frames height width\"],\n",
        "                spikes: Float[Tensor, \"num_frames num_neurons\"],\n",
        "                max_delay: int=25\n",
        "                ) -> Float[Tensor, \"max_delay height width\"]:\n",
        "    \"\"\"\n",
        "    Compute the spike triggered average (STA) for a specified neuron.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    neuron : int\n",
        "        index of the neuron\n",
        "    stimulus : Float[Tensor, \"num_frames height width\"]\n",
        "        stimulus array\n",
        "    spikes : Float[Tensor, \"num_frames num_neurons\"]\n",
        "        spike count array\n",
        "    max_delay : int\n",
        "        number of preceding frames (D) in the STA\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Float[Tensor, \"max_delay height width\"]\n",
        "        spike triggered average (STA) for the specified neuron\n",
        "    \"\"\"\n",
        "    stim_shape = stimulus.shape[1:]\n",
        "    sta = torch.zeros((max_delay,) + stim_shape)\n",
        "\n",
        "    ###\n",
        "    # YOUR CODE BELOW\n",
        "    ...\n",
        "    ###\n",
        "    return sta\n",
        "\n",
        "def plot_sta(neuron: int,\n",
        "             sta: Float[Tensor, \"max_delay height width\"],\n",
        "             n_cols: int=5\n",
        "             ) -> None:\n",
        "    \"\"\"\n",
        "    Plot the spike triggered average (STA) for a specified neuron.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    neuron : int\n",
        "        index of the neuron\n",
        "    sta : Float[Tensor, \"max_delay height width\"]\n",
        "        spike triggered average (STA) for the specified neuron\n",
        "    n_cols : int\n",
        "        number of columns in the plot\n",
        "\n",
        "    \"\"\"\n",
        "    max_delay = sta.shape[0]\n",
        "    n_rows = int(torch.ceil(torch.tensor(max_delay / n_cols)))\n",
        "\n",
        "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(4 * n_rows, 4 * n_cols))\n",
        "    vmin = sta.min()\n",
        "    vmax = sta.max()\n",
        "    for d, ax in enumerate(axs.ravel()):\n",
        "        ax.imshow(sta[d], vmin=vmin, vmax=vmax, cmap=\"Greys\")\n",
        "        ax.set_axis_off()\n",
        "        ax.set_title(\"neuron {}, {}ms pre\".format(neuron + 1, d*10))\n",
        "    for ax in axs.ravel()[max_delay:]:\n",
        "        ax.set_visible(False)\n",
        "\n",
        "n = 0\n",
        "sta = compute_sta(n, stimulus, spikes)\n",
        "plot_sta(n, sta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZVrpQLkDy1c"
      },
      "source": [
        "### Finally, create PyTorch Datasets containing the stimuli and the spikes.\n",
        "Before moving onto the modeling sections, we'll split the training stimulus and spikes into batches of length 1000 frames (10 seconds of data). Then we'll randomly assign 20% of the batches to a validation dataset. We've written a simple dataset to get the training and validation batches. For stability, we normalize the stimulus to be binary rather than 0 or 128, as in the raw data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwXE8V_b2mjN"
      },
      "outputs": [],
      "source": [
        "class RGCDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for the RGC white noise data.\n",
        "    \"\"\"\n",
        "    stimulus: Float[Tensor, \"num_frames height width\"]\n",
        "    spikes: Float[Tensor, \"num_frames num_neurons\"]\n",
        "\n",
        "    def __init__(self,\n",
        "                 stimulus: Float[Tensor, \"num_frames height width\"],\n",
        "                 spikes: Float[Tensor, \"num_frames num_neurons\"]\n",
        "                 ) -> None:\n",
        "        self.stimulus = stimulus\n",
        "        self.spikes = spikes\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the number of frames in the dataset\n",
        "        return self.stimulus.shape[0]\n",
        "\n",
        "    def __getitem__(self,\n",
        "                    idx: int\n",
        "                    ) -> Dict[str, Float[Tensor, \"...\"]]:\n",
        "        # Binarize the stimulus, move it and the spikes to the GPU,\n",
        "        # and package into a dictionary\n",
        "        x = self.stimulus[idx].to(device).type(dtype) / 128.0\n",
        "        y = self.spikes[idx].to(device)\n",
        "        return dict(stimulus=x, spikes=y)\n",
        "\n",
        "def make_datasets(batch_size: int=1000\n",
        "                  ) -> Tuple[RGCDataset, RGCDataset]:\n",
        "    \"\"\"\n",
        "    Create the training and validation datasets.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    batch_size : int\n",
        "        The number of frames in each batch.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple[RGCDataset, RGCDataset]\n",
        "        The training and validation datasets.\n",
        "    \"\"\"\n",
        "    n_batches = NUM_FRAMES // batch_size\n",
        "    batched_stimulus = stimulus[:n_batches * batch_size]\n",
        "    batched_stimulus = batched_stimulus.reshape(n_batches, batch_size, HEIGHT, WIDTH)\n",
        "    batched_spikes = spikes[:n_batches * batch_size]\n",
        "    batched_spikes = batched_spikes.reshape(n_batches, batch_size, NUM_NEURONS)\n",
        "\n",
        "    # Split into train and validation\n",
        "    torch.manual_seed(0)\n",
        "    n_train = int(0.8 * n_batches)\n",
        "    order = torch.randperm(n_batches)\n",
        "    train_stimulus = batched_stimulus[:n_train]\n",
        "    val_stimulus = batched_stimulus[n_train:]\n",
        "    train_spikes = batched_spikes[:n_train]\n",
        "    val_spikes = batched_spikes[n_train:]\n",
        "\n",
        "    train_dataset = RGCDataset(train_stimulus, train_spikes)\n",
        "    val_dataset = RGCDataset(val_stimulus, val_spikes)\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "train_dataset, val_dataset = make_datasets()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npfHppegnItd"
      },
      "source": [
        "## Part 2: Fit a linear-nonlinear Poisson (LNP) model\n",
        "\n",
        "Let's start with a simple linear-nonlinear-Poisson (LNP) model. In statistics, we would just call this a generalized linear model (GLM), but here we'll stick to the neuroscience lingo to be consistent with McIntosh et al. (2016). LNP models (and GLMs more generally) are natural models for count data, like spike counts. Whereas standard linear models could ouput negative means, these models are constrained to output non-negative expected spike counts. Moreover, since they use a Poisson noise model, the variance of the spike counts will grow with the mean, unlike in typical linear regression models.\n",
        "\n",
        "The basic LNP model is,\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbb{E}[y_{t,n} \\mid \\mathbf{X}, \\mathbf{W}_n]\n",
        "&= f \\left(\\sum_{d=1}^D \\sum_{i=1}^{P_H} \\sum_{j=1}^{P_W} x_{t-d,i,j} w_{n,d,i,j} \\right)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $\\mathbf{W}_n \\in \\mathbb{R}^{D \\times P_h \\times P_W}$ are the weights, and entry $w_{n,d,i,j}$ is the weight neuron $n$ gives to the simulus at pixel $i,j$ at $d$ frames preceding the current time. Assume the weights factor into a **spatial footprint** $\\mathbf{u}_n \\in \\mathbb{R}^{P_H \\times P_W}$ times a temporal profile $\\mathbf{v}_n \\in \\mathbb{R}^D$.\n",
        "\n",
        "$$\n",
        "w_{n,d,i,j} = v_{n,d} u_{n,i,j}\n",
        "$$\n",
        "\n",
        "Then the expected value can be written as,\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbb{E}[y_{t,n} \\mid X]\n",
        "&= f \\left( \\sum_{d=1}^D v_{n,d} \\left(\\sum_{i=1}^{P_H} \\sum_{j=1}^{P_W} x_{t-d,i,j} u_{n,i,j} \\right) \\right) \\\\\n",
        "&= f \\left( \\sum_{d=1}^D v_{n,d} \\tilde{x}_{n,t-d} \\right) \\\\\n",
        "&= f \\left( a_{t,n} \\right)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\n",
        "a_{t,n} = [\\tilde{\\mathbf{x}}_n \\star \\mathbf{v}_n]_t\n",
        "$$\n",
        "\n",
        "is the **activation** of neuron $n$ at time $t$. The activation is a cross-correlation (convolution in PyTorch) between $\\tilde{\\mathbf{x}}_{n} \\in \\mathbb{R}^T$, the stimulus projected onto the spatial filter for neuron $n$, and $\\mathbf{v}_n$, the temporal profile for neuron $n$. The mean function $f: \\mathbb{R} \\to \\mathbb{R}_+$ maps activation to a non-negative expected spike count.\n",
        "\n",
        "Once we compute $\\mathbb{E}[y_{t,n} \\mid \\mathbf{X}, \\mathbf{W}_n]$ we compute the likelihood function based on a Poisson regression model:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\log p(y_{t,n}; \\mathbf{X} \\mathbf{W}_n) &= \\mathrm{Po}(y_{t,n}; f ( a_{t,n} )) \\\\\n",
        "&= \\log f( a_{t,n})- f ( a_{t,n} ) - \\log(y_{t,n}!)\n",
        "\\\\ & = y_{t,n} a_{t,n}- \\exp ( a_{t,n} ) - \\log(y_{t,n}!)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $f(a) = e^a$.\n",
        "\n",
        "Summing across samples in $t$ leads to the full likelihood for estimating the parameters for a given neuron. We can do this simultaneously across all neurons by summing over $n$ too, as gradient descent will independently update each neuron's parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "galqOTzc2D72"
      },
      "source": [
        "### Problem 2a: Implement the model\n",
        "\n",
        "Let's start by implementing the GLM model as a class that inherits from `nn.Module`. The  `forward` method returns the mean spike count for each time bin\n",
        "given the stimulus. In the loss function below (Problem 2b), we'll pass this output to the mean of a Poisson distribution.\n",
        "\n",
        "**Notes:**\n",
        "- As in Lab 2, you should first project the stimulus onto the spatial filters with a linear layer, then you can convolve with the temporal filters.\n",
        "- Even though the spatial projection is a linear layer, we'll call it `spatial_conv` since its a factor of a spatiotemporal convolution. This naming will also be consistent with our models below.\n",
        "- Both `spatial_conv` and `temporal_conv` include a learnable bias, by default. We only need one, so turn off the bias in the spatial layer.\n",
        "- `mean_function` specifies the mapping from the linear predictor to the expected spike count. We'll use an exponential function to be consistent with the lecture, but `F.softplus` is more common in practice. (It tends to be a little more stable during training.\n",
        "- We set the initial bias to a value that is roughly the log of the average spike count so that our initial means are in the right ballpark.\n",
        "- We'll add a small positive constant to the firing rate in the `forward` function to ensure that we don't get `log(0)` errors during training.\n",
        "- `forward` takes a keyword argument `spikes`. We won't use it in this model, but we need it here so that our training algorithm will work for this model as well as the later ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jpvF4v_0Iam"
      },
      "outputs": [],
      "source": [
        "class LNP(nn.Module):\n",
        "    \"\"\"\n",
        "    A linear-nonlinear-Poisson (LNP) model for RGC data, as described above.\n",
        "\n",
        "    The model consists of a linear filter (spatial and temporay convolution) followed by\n",
        "    a nonlinear function to produce the mean of a Poisson spike count distribution.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_neurons : int\n",
        "        The number of neurons in the model.\n",
        "    height : int\n",
        "        The height of the stimulus in pixels.\n",
        "    width : int\n",
        "        The width of the stimulus in pixels.\n",
        "    max_delay : int\n",
        "        The maximum delay in frames for the temporal convolution.\n",
        "    mean_function : callable\n",
        "        The function to compute the mean of the Poisson distribution.\n",
        "    initial_bias : float\n",
        "        The initial bias for the temporal convolution.\n",
        "    spatial_conv : nn.Linear\n",
        "        The linear layer for the spatial convolution.\n",
        "    temporal_conv : nn.Conv1d\n",
        "        The convolutional layer for the temporal convolution.\n",
        "    \"\"\"\n",
        "    num_neurons: int\n",
        "    height: int\n",
        "    width: int\n",
        "    max_delay: int\n",
        "    mean_function: callable\n",
        "    initial_bias: float\n",
        "    spatial_conv: nn.Linear\n",
        "    temporal_conv: nn.Conv1d\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_neurons=NUM_NEURONS,\n",
        "                 height=HEIGHT,\n",
        "                 width=WIDTH,\n",
        "                 max_delay=MAX_DELAY,\n",
        "                 mean_function=torch.exp,\n",
        "                 initial_bias=0.05):\n",
        "        super(LNP, self).__init__()\n",
        "        self.num_neurons = num_neurons\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.max_delay = max_delay\n",
        "        self.mean_function = mean_function\n",
        "\n",
        "        ###\n",
        "        # YOUR CODE BELOW\n",
        "        #\n",
        "        self.spatial_conv = nn.Linear(...)\n",
        "        self.temporal_conv = nn.Conv1d(...)\n",
        "        #\n",
        "        ###\n",
        "\n",
        "        # Initialize the bias\n",
        "        torch.nn.init.constant_(self.temporal_conv.bias,\n",
        "                                torch.log(torch.tensor(initial_bias)))\n",
        "\n",
        "    def forward(self,\n",
        "                stimulus: Float[Tensor, \"num_frames height width\"],\n",
        "                spikes: Optional[Float[Tensor, \"num_frames num_neurons\"]]=None\n",
        "                ) -> Float[Tensor, \"num_frames num_neurons\"]:\n",
        "        \"\"\"\n",
        "        Compute the expected spike counts for a given stimulus.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        stimulus : Float[Tensor, \"num_frames height width\"]\n",
        "            The stimulus to be processed.\n",
        "        spikes : Float[Tensor, \"num_frames num_neurons\"], optional\n",
        "            The spike counts for the neurons. This is NOT USED in the model,\n",
        "            but is included for compatibility with the training loop.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Float[Tensor, \"num_frames num_neurons\"]\n",
        "            The expected spike counts for the neurons.\n",
        "\n",
        "        \"\"\"\n",
        "        ###\n",
        "        # YOUR CODE BELOW\n",
        "        #\n",
        "        x = stimulus\n",
        "        ...\n",
        "        ###\n",
        "\n",
        "        return 1e-4 + x\n",
        "\n",
        "\n",
        "def check_model_outputs(model):\n",
        "    \"\"\"\n",
        "    Check that the model outputs are the right shape and non-negative.\n",
        "    \"\"\"\n",
        "    out = model(train_dataset[0]['stimulus'],\n",
        "                train_dataset[0]['spikes'])\n",
        "    assert out.shape == train_dataset[0]['spikes'].shape\n",
        "    assert torch.all(out > 0)\n",
        "\n",
        "# Construct an LNP model with random initial weights.\n",
        "# Fix the seed so that the tests below will work\n",
        "torch.manual_seed(0)\n",
        "lnp = LNP().to(device)\n",
        "check_model_outputs(lnp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8kdQJmogGI_"
      },
      "source": [
        "### Problem 2b: Implement the Poisson loss\n",
        "Compute the average negative log likelihood of the spikes (taking the mean over neurons and frames) given the expected spike counts (`rates`) ouput by the model.\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathcal{L}(\\mathbf{W}) = -\\frac{1}{NT} \\sum_{n=1}^N \\sum_{t=1}^T \\log \\mathrm{Po}(y_{t,n} \\mid f(a_{t,n})\n",
        "\\end{aligned}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwzhpHNQI73j"
      },
      "outputs": [],
      "source": [
        "def poisson_loss(rate: Float[Tensor, \"num_frames num_neurons\"],\n",
        "                 spikes: Float[Tensor, \"num_frames num_neurons\"]):\n",
        "    \"\"\"Compute the log-likelihood under a Poisson spiking model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    rate: Float[Tensor, \"num_frames num_neurons\"]\n",
        "        The expected spike counts for the neurons.\n",
        "    spikes: Float[Tensor, \"num_frames num_neurons\"]\n",
        "        The actual spike counts for the neurons.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Float[Tensor, \"num_frames num_neurons\"]\n",
        "        The negative log likelihood of the Poisson distribution.\n",
        "        This is the loss function for the LNP and subsequent GLM models.\n",
        "\n",
        "    \"\"\"\n",
        "    ###\n",
        "    # YOUR CODE BELOW\n",
        "    avg_nll = ...\n",
        "    ###\n",
        "\n",
        "    return avg_nll\n",
        "\n",
        "assert torch.isclose(\n",
        "    poisson_loss(lnp(train_dataset[0]['stimulus']),\n",
        "                 train_dataset[0]['spikes']),\n",
        "    torch.tensor(0.2675), atol=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFip8dPMQVXk"
      },
      "source": [
        "### Problem 2c: Add $\\ell_2$ weight regularization\n",
        "\n",
        "To the Poisson loss above, we'll add a regularization penalty on the squared $\\ell_2$ norm of the weights,\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathcal{R}(\\mathbf{W}) &= \\frac{\\alpha}{2} \\sum_{n=1}^N (\\|\\mathbf{u}_n\\|_F^2 + \\|\\mathbf{v}_n\\|_F^2)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $\\mathbf{u}_n$ and $\\mathbf{v}_n$ are the spatial and temporal weights for neuron $n$, respectively, and $\\alpha$ is a scaling factor.\n",
        "\n",
        "Do not regularize the biases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdP8kBeXBcY3"
      },
      "outputs": [],
      "source": [
        "def lnp_regularizer(model: LNP,\n",
        "                    alpha: float=1e-3\n",
        "                    ) -> float:\n",
        "    \"\"\"\n",
        "    Compute the log prior probability under a mean-zero Gaussian model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: LNP\n",
        "        The LNP model to be regularized.\n",
        "    alpha: float\n",
        "        The regularization strength.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        The regularization term for the model. This is the sum of the\n",
        "        squared weights of the spatial and temporal convolution filters.\n",
        "\n",
        "    \"\"\"\n",
        "    ###\n",
        "    # YOUR CODE BELOW\n",
        "    reg = ...\n",
        "    ###\n",
        "\n",
        "    return reg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZvRQVcQhoIY"
      },
      "source": [
        "### Fit the LNP model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "fb5dedd1a4764fc4ad187a4f77dbcaa5",
            "b2aad7bcc7254b26a7951a24add9ea7b",
            "eabcf03b26b142d3b849d284caa0955f",
            "fd3b5bda042d47edb597c6ea54c90606",
            "3c521c0e0f7a47f583c5ba6aeda5492e",
            "f32a4e5559d64966b914fba84305216f",
            "ae22c15e520f4a149403e9095dbcb8bf",
            "f504679020204485b7645c1d2b5f05ab",
            "6b98ce79453a4070a924993ca7bdc70a",
            "7908b0b0661a4ca593ec68d8c206c32c",
            "ce1ddf8a7e03430ea4dbfe22691a8de2",
            "592814803c544c39a175c59bf8e19cf5",
            "79e3be6801cf4c8fb5821e8ea664153d",
            "683bf0756c8f40259cfcbe1f67be953b",
            "fb9ef62a36c24792a3ae2653d5dd214a",
            "74a436427ce0499f842b5b4b22e898ba",
            "a144676824dc43a69191034a8623acdf",
            "39bb3e670e00451e8b3f6e0293efd559",
            "a3875ce614724e269a2715a5a6a9a123",
            "61a8ed6b241c4b949daf89c251521944",
            "a9be2e4ce8314b0b8cb56196b1cacc59",
            "39d6d8998fd846cab8eb3d1181d9c50f"
          ]
        },
        "id": "Bb0YF6BnhrWy",
        "outputId": "376e61eb-9010-4408-a0ff-9f7d2b43538c"
      },
      "outputs": [],
      "source": [
        "# Construct an LNP model with random initial weights.\n",
        "torch.manual_seed(0)\n",
        "lnp = LNP().to(device)\n",
        "\n",
        "# Fit the LNP model\n",
        "print(\"Training LNP model. This should take about 2 minutes...\")\n",
        "train_losses, val_losses = \\\n",
        "    train_model(lnp,\n",
        "                train_dataset,\n",
        "                val_dataset,\n",
        "                poisson_loss,\n",
        "                lnp_regularizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjPchkKjEAXk"
      },
      "source": [
        "### Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "-OvCUpMQ9jQC",
        "outputId": "899ff410-d911-4631-c335-7879334084aa"
      },
      "outputs": [],
      "source": [
        "# Plot the training and validation curves\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].plot(train_losses, color=palette[0], label=\"train\")\n",
        "axs[0].plot(val_losses, color=palette[1], ls='--', label=\"validation\")\n",
        "axs[0].set_xlabel(\"epoch\")\n",
        "axs[0].set_ylabel(\"poisson loss\")\n",
        "axs[0].grid(True)\n",
        "axs[0].legend(loc=\"upper right\")\n",
        "\n",
        "axs[1].plot(train_losses, color=palette[0], label=\"train\")\n",
        "axs[1].plot(val_losses, color=palette[1], ls='--', label=\"validation\")\n",
        "axs[1].set_xlabel(\"epoch\")\n",
        "axs[1].set_ylabel(\"poisson loss\")\n",
        "axs[1].set_ylim(top=val_losses[20])\n",
        "axs[1].grid(True)\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "03g-_aoE06tj",
        "outputId": "ae05748e-882f-44d7-fc61-7e3136f2af7d"
      },
      "outputs": [],
      "source": [
        "plot_stimulus_weights(lnp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xABSxqSLWNI8"
      },
      "source": [
        "### Problem 2d: [Short Answer] Interpret the results\n",
        "\n",
        "How do the spatiotemporal filters relate to the STA from Problem 1c? Are they mathematically related?\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P2uD55Iizjk"
      },
      "source": [
        "\n",
        "_Your answer here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2uyT_J3up4u"
      },
      "source": [
        "## Part 3: Fit a GLM with inter-neuron couplings\n",
        "\n",
        "Now add inter-neuron couplings to the basic model above. For historical reasons, the LNP with inter-neuron couplings is what some neuroscientists call a GLM, even though they're both instances of generalized linear models! Again, we're just going to stick to the notation of McIntosh et al (2016) for this lab anyway.  \n",
        "\n",
        "The new model has activation,\n",
        "\n",
        "$$\n",
        "a_{t,n}\n",
        "= [\\tilde{\\mathbf{x}}_n \\star \\mathbf{v}_n]_t +  \\sum_{m=1}^N \\sum_{d=1}^D y_{t-d,m} g_{m,n,d}\n",
        "$$\n",
        "\n",
        "where $\\mathbf{G} \\in \\mathbb{R}^{N \\times N \\times D}$ is a tensor of **coupling** weights.\n",
        "\n",
        "You can implement the activation using a convolution of $\\mathbf{Y}$ and $\\mathbf{G}$.\n",
        "\n",
        "**Note:** as above, the `coupling_conv` will have a bias by default. Get rid of it. You don't need it since there's already a bias in the `temporal_conv`.\n",
        "\n",
        "**IMPORTANT:** Make sure your output only depends on spike counts up to but _not including_ time $t$!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL9nCdv3yuTx"
      },
      "source": [
        "### Problem 3a: Implement the coupled model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McoqFbRkp4s2"
      },
      "outputs": [],
      "source": [
        "class GLM(nn.Module):\n",
        "    \"\"\"\n",
        "    A generalized linear model (GLM) with a spatiotemporal filter\n",
        "    and coupling weights. The model consists of a linear filter (spatial and\n",
        "    temporal convolution) followed by a nonlinear function to produce the mean\n",
        "    of a Poisson spike count distribution. The model also includes coupling\n",
        "    weights to account for the influence of other neurons on the firing rate\n",
        "    of a neuron.\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_neurons : int\n",
        "        The number of neurons in the model.\n",
        "    height : int\n",
        "        The height of the stimulus in pixels.\n",
        "    width : int\n",
        "        The width of the stimulus in pixels.\n",
        "    max_delay : int\n",
        "        The maximum delay in frames for the temporal convolution.\n",
        "    mean_function : callable\n",
        "        The function to compute the mean of the Poisson distribution.\n",
        "    initial_bias : float\n",
        "        The initial bias for the temporal convolution.\n",
        "    spatial_conv : nn.Linear\n",
        "        The linear layer for the spatial convolution.\n",
        "    temporal_conv : nn.Conv1d\n",
        "        The convolutional layer for the temporal convolution.\n",
        "    coupling_conv : nn.Conv1d\n",
        "        The convolutional layer for the coupling weights.\n",
        "    \"\"\"\n",
        "    num_neurons: int\n",
        "    height: int\n",
        "    width: int\n",
        "    max_delay: int\n",
        "    mean_function: callable\n",
        "    spatial_conv: nn.Linear\n",
        "    temporal_conv: nn.Conv1d\n",
        "    coupling_conv: nn.Conv1d\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_neurons: int=NUM_NEURONS,\n",
        "                 height: int=HEIGHT,\n",
        "                 width: int=WIDTH,\n",
        "                 max_delay: int=MAX_DELAY,\n",
        "                 initial_bias: float=0.05,\n",
        "                 mean_function: callable=torch.exp\n",
        "                 ) -> None:\n",
        "        super(GLM, self).__init__()\n",
        "        self.num_neurons = num_neurons\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.max_delay = max_delay\n",
        "        self.mean_function = mean_function\n",
        "\n",
        "        ###\n",
        "        # YOUR CODE BELOW\n",
        "        #\n",
        "        self.spatial_conv = nn.Linear(...)\n",
        "        self.temporal_conv = nn.Conv1d(...)\n",
        "        self.coupling_conv = nn.Conv1d(...)\n",
        "        ###\n",
        "\n",
        "        # Initialize the bias\n",
        "        torch.nn.init.constant_(self.temporal_conv.bias,\n",
        "                                torch.log(torch.tensor(initial_bias)))\n",
        "\n",
        "    def forward(self,\n",
        "                stimulus: Float[Tensor, \"num_frames height width\"],\n",
        "                spikes: Float[Tensor, \"num_frames num_neurons\"]\n",
        "                ) -> Float[Tensor, \"num_frames num_neurons\"]:\n",
        "        \"\"\"\n",
        "        Compute the expected spike counts for a given stimulus and spikes.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        stimulus: Float[Tensor, \"num_frames height width\"]\n",
        "            The stimulus to be processed.\n",
        "        spikes: Float[Tensor, \"num_frames num_neurons\"]\n",
        "            The spike counts for the neurons. This is used to compute the\n",
        "            coupling weights.\n",
        "        Returns\n",
        "        -------\n",
        "        Float[Tensor, \"num_frames num_neurons\"]\n",
        "            The expected spike counts for the neurons.\n",
        "\n",
        "        \"\"\"\n",
        "        x, y = stimulus, spikes\n",
        "\n",
        "        ###\n",
        "        # YOUR CODE BELOW\n",
        "        rate = ...\n",
        "        ###\n",
        "\n",
        "        # Apply the nonlinearity and add small positive bias\n",
        "        return 1e-4 + rate\n",
        "\n",
        "# Construct a coupled GLM model with random initial weights.\n",
        "torch.manual_seed(0)\n",
        "glm = GLM().to(device)\n",
        "check_model_outputs(glm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLjycnQuy8Nj"
      },
      "source": [
        "### Problem 3b: Implement a regularizer for the coupled GLM weights\n",
        "\n",
        "Put an $\\ell_2$ penalty on the weights of the `spatial_conv`, `temporal_conv`, and `coupling_conv`. No need to regularize the bias. Scale the regularization by $\\alpha$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_bmk5eqsvCF"
      },
      "outputs": [],
      "source": [
        "def glm_regularizer(model: GLM,\n",
        "                    alpha: float=1e-3\n",
        "                    ) -> float:\n",
        "    \"\"\"\n",
        "    Implement an \\ell_2 penalty on the norm of the model weights,\n",
        "    as described above.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: GLM\n",
        "        The GLM model to be regularized.\n",
        "    alpha: float\n",
        "        The regularization strength.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        The regularization term for the model. This is the sum of the\n",
        "        squared weights of the spatial, temporal, and coupling convolution\n",
        "        filters.\n",
        "    \"\"\"\n",
        "    ###\n",
        "    # YOUR CODE BELOW\n",
        "    reg = ...\n",
        "    ###\n",
        "\n",
        "    return reg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYywYbtitPQZ"
      },
      "source": [
        "### Fit the GLM model with couplings between neurons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "389787c5e18642929573351d2def2252",
            "47cfa8f0a172427a82ace691bcd255b0",
            "17b83db809c54d4eb0d0496a4b0734fe",
            "cbcf22966c714c6f8c4026fa000a7e96",
            "871d1504891a42c09086aa35dc34e9b2",
            "a9527d3e1a604df7b1734c68aeb79c01",
            "79d7ecc6980b4e3ea0359d6fa6cdc4c7",
            "6a67d351db63442db8024a0a13680b7b",
            "79e30295dd2b4a8a8558a919cb83e0ce",
            "d871b7c368ce4975aaff90f036f673ca",
            "9226c1e375b046b3aeb59849ef41c3de",
            "87c3d51ed95e45fc8f7aa5f41fab7625",
            "58a95d7eea2b4d9683733e359bbde087",
            "d4c5042b515e4abba1f67650c9342e77",
            "c8bc97a69db94e7f9fe98802817b0b4b",
            "87051ac03e9049cdbe8c2fab59a0515e",
            "a4b1169b9253457e8c4bfd8b62fc2f95",
            "8c7668d2a36647c094bbbbe1d8576f9e",
            "b4c5f13ac13a42428cc8e69e54667f1b",
            "9be83304288947fdbed7b94f6779eb34",
            "b005280b25a842ce8a3e1c9306120764",
            "804609d813bd42b8b854b2db57407d46"
          ]
        },
        "id": "fbC-Y1BhtOkb",
        "outputId": "92d35a7c-456d-4a0c-892f-6ccb14ff646c"
      },
      "outputs": [],
      "source": [
        "# Construct a coupled GLM model with random initial weights.\n",
        "torch.manual_seed(0)\n",
        "glm = GLM().to(device)\n",
        "\n",
        "# Fit the model\n",
        "print(\"Training coupled GLM. This should take about 2-4 minutes...\")\n",
        "train_losses, val_losses = \\\n",
        "    train_model(glm,\n",
        "                train_dataset,\n",
        "                val_dataset,\n",
        "                poisson_loss,\n",
        "                glm_regularizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOV3xBHAgkHU"
      },
      "source": [
        "### Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "g7RtWo53CMi9",
        "outputId": "6f796df0-74fb-4e42-b90e-5c30b2ae7b89"
      },
      "outputs": [],
      "source": [
        "# Plot the training and validation curves\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].plot(train_losses, color=palette[0], label=\"train\")\n",
        "axs[0].plot(val_losses, color=palette[1], ls='--', label=\"validation\")\n",
        "axs[0].set_xlabel(\"epoch\")\n",
        "axs[0].set_ylabel(\"poisson loss\")\n",
        "axs[0].grid(True)\n",
        "axs[0].legend(loc=\"upper right\")\n",
        "\n",
        "axs[1].plot(train_losses, color=palette[0], label=\"train\")\n",
        "axs[1].plot(val_losses, color=palette[1], ls='--', label=\"validation\")\n",
        "axs[1].set_xlabel(\"epoch\")\n",
        "axs[1].set_ylabel(\"poisson loss\")\n",
        "axs[1].set_ylim(top=val_losses[20])\n",
        "axs[1].grid(True)\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wEviXKwBep5m",
        "outputId": "8b5e586a-08ce-447b-fcb9-652fc1a7810d"
      },
      "outputs": [],
      "source": [
        "plot_stimulus_weights(glm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "jG-oC8mmevo_",
        "outputId": "47c0fce5-b767-4166-87e7-a298c3303982"
      },
      "outputs": [],
      "source": [
        "plot_coupling_weights(glm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjk8WqT5W5gB"
      },
      "source": [
        "### Problem 3c: [Short Answer] Interpret the results\n",
        "\n",
        "Did adding the coupling weights change the spatiotemporal stimulus filters in any perceptible way? Do you see any interesting structure in the coupling weights? What other regularization strategies could you have applied to the coupling weights?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKh7IrfLq4Kd"
      },
      "source": [
        "\n",
        "_Your answer here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSpKiGqFv8U6"
      },
      "source": [
        "## Part 4: Convolutional neural network model\n",
        "\n",
        "Finally, we'll implement a convolutional neural network like the one proposed in McIntosh et al (2016). (See above.) We'll make some slight modifications though, so that the model doesn't take so long to fit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faWvElPLYqgD"
      },
      "source": [
        "### Problem 4a: Implement the convolutional model\n",
        "\n",
        "Implement the following model:\n",
        "\n",
        "1. **Apply a rank-1 spatiotemporal filter to the video:**\n",
        "\n",
        "    a.  First convolve with 2D receptive fields of size `rf_size_1` and `num_subunits_1` output channels. You do not need to pad the edges since the neurons respond primarily to the center of the video. Your output should be `T x N1 x H1 x W1` where `T` is the number of frames, `N1` is the number of subunits, and `H1,W1` are the height and width after 2D convolution without padding.\n",
        "\n",
        "    b.  Then convolve each subunit and pixel with a temporal filter, to get another `T x N1 x H1 x W1` output.\n",
        "\n",
        "    c.  Apply a rectifying nonlinearity (`F.relu`).\n",
        "\n",
        "2. **Spatial convolution and mixing**\n",
        "\n",
        "    a.  Apply a spatial convolution of size `rf_size_2` with `num_subunits_2` output channels. This layer mixes the subunits from the first layer to obtain a representation that is, hopefully, somewhat similar to that of intermediate cells in the retina.\n",
        "    \n",
        "    b.  Apply another rectifying nonlinearity (`F.relu`). The output should be `T x N2 x H2 x W2` where `N2` is the number of subunits in the second layer and `H2,W2` are the size of the image after convolution without padding.\n",
        "\n",
        "3. **Predict expected spike counts**\n",
        "\n",
        "    a. Apply a linear read-out to the `N2 x H2 x W2` representation and pass through the mean function to obtain a `T x N` tensor of expected spike counts, where `N` is the number of neurons.\n",
        "\n",
        "\n",
        "**Notes:** The modifications we made are\n",
        "\n",
        "- We used slightly larger receptive field sizes. This actually speeds things up since, with valid padding, we end up with fewer \"pixels\" in subsequent layers.\n",
        "\n",
        "- We used a smaller number of subunits (4/4 as opposed to 8/16). This is a smaller dataset (only 9 neurons) and we seemed to overfit with more layers.\n",
        "\n",
        "- We use an exponential mean function to be consistent with the models above. Again, a softplus is more common in practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-DUYEogxe-8"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    \"\"\"\n",
        "    A convolutional neural network (CNN) model for RGC data, as described above.\n",
        "    The model consists of a series of convolutional layers followed by a\n",
        "    fully connected layer to produce the mean of a Poisson spike count\n",
        "    distribution. The model also includes a nonlinear activation function\n",
        "    between layers to capture nonlinear features of the stimulus.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_neurons : int\n",
        "        The number of neurons in the model.\n",
        "    height : int\n",
        "        The height of the stimulus in pixels.\n",
        "    width : int\n",
        "        The width of the stimulus in pixels.\n",
        "    max_delay : int\n",
        "        The maximum delay in frames for the temporal convolution.\n",
        "    rf_size_1 : int\n",
        "        The size of the receptive field for the first layer.\n",
        "    rf_size_2 : int\n",
        "        The size of the receptive field for the second layer.\n",
        "    num_subunits_1 : int\n",
        "        The number of subunits in the first layer.\n",
        "    num_subunits_2 : int\n",
        "        The number of subunits in the second layer.\n",
        "    mean_function : callable\n",
        "        The function to compute the mean of the Poisson distribution.\n",
        "    initial_bias : float\n",
        "        The initial bias for the temporal convolution.\n",
        "    spatial_conv : nn.Conv2d\n",
        "        The convolutional layer for the spatial convolution.\n",
        "    temporal_conv : nn.Conv1d\n",
        "        The convolutional layer for the temporal convolution.\n",
        "    layer2 : nn.Conv2d\n",
        "        The convolutional layer for the second layer.\n",
        "    layer3 : nn.Linear\n",
        "        The fully connected layer for the output.\n",
        "    \"\"\"\n",
        "    num_neurons: int\n",
        "    height: int\n",
        "    width: int\n",
        "    max_delay: int\n",
        "    rf_size_1: int\n",
        "    rf_size_2: int\n",
        "    num_subunits_1: int\n",
        "    num_subunits_2: int\n",
        "    mean_function: callable\n",
        "    spatial_conv: nn.Conv2d\n",
        "    temporal_conv: nn.Conv1d\n",
        "    layer2: nn.Conv2d\n",
        "    layer3: nn.Linear\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_neurons: int=NUM_NEURONS,\n",
        "                 height: int=HEIGHT,\n",
        "                 width: int=WIDTH,\n",
        "                 rf_size_1: int=21,\n",
        "                 rf_size_2: int=15,\n",
        "                 max_delay: int=MAX_DELAY,\n",
        "                 num_subunits_1: int=4,\n",
        "                 num_subunits_2: int=4,\n",
        "                 initial_bias: float=0.05,\n",
        "                 mean_function: callable=torch.exp):\n",
        "\n",
        "        super(CNN, self).__init__()\n",
        "        self.num_neurons = num_neurons\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.max_delay = max_delay\n",
        "        self.rf_size_1 = rf_size_1\n",
        "        self.rf_size_2 = rf_size_2\n",
        "        self.num_subunits_1 = num_subunits_1\n",
        "        self.num_subunits_2 = num_subunits_2\n",
        "        self.mean_function = mean_function\n",
        "\n",
        "        ###\n",
        "        # YOUR CODE BELOW\n",
        "        #\n",
        "        self.spatial_conv = nn.Conv2d(...)\n",
        "        self.temporal_conv = nn.Conv1d(...)\n",
        "        self.layer2 = nn.Conv2d(...)\n",
        "        self.layer3 = nn.Linear(...)\n",
        "        #\n",
        "        ###\n",
        "\n",
        "        # Initialize the bias\n",
        "        torch.nn.init.constant_(self.layer3.bias,\n",
        "                                torch.log(torch.tensor(initial_bias)))\n",
        "\n",
        "    def forward(self,\n",
        "                stimulus: Float[Tensor, \"num_frames height width\"],\n",
        "                spikes: Optional[Float[Tensor, \"num_frames num_neurons\"]]=None\n",
        "                ) -> Float[Tensor, \"num_frames num_neurons\"]:\n",
        "        \"\"\"\n",
        "        Compute the expected spike counts for a given stimulus and spikes.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        stimulus: Float[Tensor, \"num_frames height width\"]\n",
        "            The stimulus to be processed.\n",
        "        spikes: Float[Tensor, \"num_frames num_neurons\"]\n",
        "            The spike counts for the neurons. This is NOT USED in this model,\n",
        "            but is included for compatibility with the training loop.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Float[Tensor, \"num_frames num_neurons\"]\n",
        "            The expected spike counts for the neurons.\n",
        "\n",
        "        \"\"\"\n",
        "        x = stimulus\n",
        "        ###\n",
        "        # YOUR CODE BELOW\n",
        "        rate = ...\n",
        "        ###\n",
        "\n",
        "        return 1e-4 + rate\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "cnn = CNN().to(device)\n",
        "check_model_outputs(cnn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKOZi-lZLREY"
      },
      "source": [
        "### Problem 4b: Regularize the weights\n",
        "\n",
        "Put an $\\ell_2$ penalty on the weights of `spatial_conv`, `temporal_conv`, `layer2`, and `layer3`. Scale the regularize by $\\alpha$, as in the preceding sections. No need to regularize the biases. We found that a smaller value of $\\alpha$ was helpful, so here we default to `1e-5`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLSd4T5rHKyL"
      },
      "outputs": [],
      "source": [
        "# Regularize the weights of the CNN\n",
        "def cnn_regularizer(model: CNN,\n",
        "                    alpha: float=1e-5\n",
        "                    ) -> float:\n",
        "    \"\"\"\n",
        "    Implement an \\ell_2 penalty on the norm of the model weights,\n",
        "    as described above.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: CNN\n",
        "        The CNN model to be regularized\n",
        "    alpha: float\n",
        "        The regularization strength.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        The regularization term for the objective. This is the sum of the\n",
        "        squared weights of the spatial, temporal, and coupling convolution\n",
        "        filters.\n",
        "    \"\"\"\n",
        "    ###\n",
        "    # YOUR CODE BELOW\n",
        "    reg = ...\n",
        "    #\n",
        "    ###\n",
        "\n",
        "    return reg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNJj40mULrFa"
      },
      "source": [
        "### Fit the CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "f97e9022073443cfa4d7bead9422d9c8",
            "4471dfe5509a498f9ed63a28a32f0a25",
            "28df8a7d42a94da48fdee6d330b0f7f2",
            "98c579ecfb5048d78b96af1c1d68859c",
            "40cf2b5e1b344828bb1c79c17f98518d",
            "108bf087491648cd81e110c8f58c8c69",
            "ffaff15efd0e402c954706b65544377d",
            "ed0c6842df2d4ae78f1bf99c0351c1f7",
            "85627365d0d04505b7f5db266fb10856",
            "9ca08f8dacfd4775a20abe1354b3a221",
            "e1533b201c6b451e98117a6ca54ca0fe",
            "207e63074bb2407591840ac7a1905a49",
            "7b18e1ccdaa747a78b4ea19fbd9771a1",
            "ab8b8848834e40878356c25898fb4f79",
            "6eb77ec2f2124403a1cf0c0e383a0da4",
            "951f53f87c1e4a75b6de2b67c0619e9d",
            "3b88f8dc29a244a8ae4b30ac94cc1396",
            "b333a22481684c9299ec595acfc2d096",
            "e036da5497f740bf9db8ae335d945ae2",
            "312347177b0249aa8fbe0366385d6658",
            "470450fee2fd4cbfbb515632711c2822",
            "7c03892a105940429c08ab086b5bbbc9"
          ]
        },
        "id": "Mg9epbov_2jQ",
        "outputId": "e892c972-d5dd-4cfe-dfcc-c786f86e314e"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "cnn = CNN().to(device)\n",
        "\n",
        "print(\"Fitting the CNN model. This should take about 10-20 minutes.\")\n",
        "train_losses, val_losses = \\\n",
        "    train_model(cnn,\n",
        "                train_dataset,\n",
        "                val_dataset,\n",
        "                poisson_loss,\n",
        "                cnn_regularizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBBKfnSyENd8"
      },
      "source": [
        "### Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "sxIFl9tGSVz7",
        "outputId": "88bb1d9d-3e3c-46fb-e432-cc8b489a2f43"
      },
      "outputs": [],
      "source": [
        "# Plot the training and validation curves\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].plot(train_losses, color=palette[0], label=\"train\")\n",
        "axs[0].plot(val_losses, color=palette[1], ls='--', label=\"validation\")\n",
        "axs[0].set_xlabel(\"epoch\")\n",
        "axs[0].set_ylabel(\"poisson loss\")\n",
        "axs[0].grid(True)\n",
        "axs[0].legend(loc=\"upper right\")\n",
        "\n",
        "axs[1].plot(train_losses, color=palette[0], label=\"train\")\n",
        "axs[1].plot(val_losses, color=palette[1], ls='--', label=\"validation\")\n",
        "axs[1].set_xlabel(\"epoch\")\n",
        "axs[1].set_ylabel(\"poisson loss\")\n",
        "axs[1].set_ylim(top=val_losses[10])\n",
        "axs[1].grid(True)\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euh6Qpao6qe2"
      },
      "source": [
        "### Plot the subunit weights for the CNN\n",
        "\n",
        "First we'll plot the spatiotemporal filters of the first layer of subunits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "drsWoCfJ4_yV",
        "outputId": "bb0fa72d-63c0-40b9-e0bc-d13264646cc1"
      },
      "outputs": [],
      "source": [
        "plot_cnn_subunits_1(cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPqMs_u5MkYM"
      },
      "source": [
        "### Plot the spatial weights for the second layer of subunits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "H7G8BFgI4vIE",
        "outputId": "f328be16-2933-4e55-d343-f0f0e26db255"
      },
      "outputs": [],
      "source": [
        "plot_cnn_subunits2(cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N6nOINb8E9w"
      },
      "source": [
        "### Problem 4c: Predict test firing rates\n",
        "\n",
        "Finally, take the fitted models from Parts 2-4 and evaluate them on test data.\n",
        "\n",
        "The test data consists of _expected_ spike counts rather than spike counts. That's because they showed the same visual stimulus many times and computed the average response.  If our models are working well, they should output a similar firing rate in response to that same visual stimulus.\n",
        "\n",
        "**Note:** technically the coupled GLM from Part 3 expects preceding spikes as input, but here we'll give it the rates as input instead. (We don't have test spikes to feed in.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GgfQzkXs8VK3",
        "outputId": "3a908224-286f-453b-af8c-50ae836bfd74"
      },
      "outputs": [],
      "source": [
        "# Move the test stimulus and measured rates to the GPU\n",
        "test_stimulus_cuda = test_stimulus.to(device).type(dtype) / 128.0\n",
        "test_rates_cuda = test_rates.to(device)\n",
        "\n",
        "###\n",
        "# YOUR CODE BELOW\n",
        "#\n",
        "lnp_test_rates = ...\n",
        "glm_test_rates = ...\n",
        "cnn_test_rates = ...\n",
        "\n",
        "# Plot a slice of the true and predicted firing rates\n",
        "...\n",
        "#\n",
        "###\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQEng0FgNBzG"
      },
      "source": [
        "### Problem 4d: Model comparison\n",
        "\n",
        "Make a bar plot of the mean squared error between the true and predicted rates for each model. As a baseline, compute the mean squared error of a constant-rate model with rate equal to the expected spike count under the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "JBDTFUTm_HlN",
        "outputId": "019862b4-e90a-4628-ca50-9cfc08444252"
      },
      "outputs": [],
      "source": [
        "###\n",
        "# YOUR CODE BELOW\n",
        "#\n",
        "mse_const = ...\n",
        "mse_lnp = ...\n",
        "mse_glm = ...\n",
        "mse_cnn = ...\n",
        "#\n",
        "###\n",
        "\n",
        "# Make a bar plot\n",
        "plt.bar(0, mse_const, color='gray', ec='k')\n",
        "plt.bar(1, mse_lnp, color=palette[0], ec='k')\n",
        "plt.bar(2, mse_glm, color=palette[1], ec='k')\n",
        "plt.bar(3, mse_cnn, color=palette[2], ec='k')\n",
        "plt.xticks([0, 1, 2, 3], [\"Const.\", \"LNP\", \"GLM\", \"CNN\"])\n",
        "plt.ylabel(\"Test MSE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsadGfnrCO5o"
      },
      "source": [
        "## Part 5: Discussion\n",
        "\n",
        "You've now developed and fit three encoding models for these retinal ganglion cell responses, and hopefully you've developed some intuition for how these models work! Let's end by discussing some of the decisions that go into building and checking these models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH60uICPobwL"
      },
      "source": [
        "### Problem 5a\n",
        "All three models were fit with a Poisson loss, which has unit dispersion. What is overdispersion of count data? Is this an issue here?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdVWp1Iaol-M"
      },
      "source": [
        "_Your answer here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgmXy_ZwolA8"
      },
      "source": [
        "### Problem 5b\n",
        "The CNN was loosely motivated as an approximation to the layers of photoreceptors, bipolar cells, etc. that precede retinal ganglion cells. Of course, the actual circuitry is more complicated. What could you imagine adding to this model to make it more realistic?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24Q_Y1phornk"
      },
      "source": [
        "_Your answer here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLruEbXWorAh"
      },
      "source": [
        "### Problem 5c\n",
        "In our hands, the CNN outperformed the LNP and GLM. Though it's tempting to just say the CNN is a more flexible model, notice that the CNN does not have coupling filters and it compresses the input substantially before the final read-out layer. Given the results above, what follow-up experiments would you do to further understand the root of these performance differences?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe7F1Bgcov1e"
      },
      "source": [
        "_Your answer here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCL51swyoviG"
      },
      "source": [
        "### Problem 5d\n",
        "We didn't ask you to do a thorough hyperparameter search. If you were to do one, what are the key parameters you would vary to try to improve model performance?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_zO70J0ozAM"
      },
      "source": [
        "_Your answer here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzqI_1IzoyvS"
      },
      "source": [
        "### Problem 5e\n",
        "\n",
        "We fit all of these models to RGC responses to a binary white noise stimulus. Would you expect your results to change if the cells had been shown a movie with natural scenes instead?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjus5y__o26D"
      },
      "source": [
        "_Your answer here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pohv6Wado5Li"
      },
      "source": [
        "## Author contributions\n",
        "\n",
        "Write a short paragraph describing how each team member contributed to this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH5e9UTBo_Rj"
      },
      "source": [
        "_Your answer here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjisiMLhQxaN"
      },
      "source": [
        "## Submission Instructions\n",
        "\n",
        "\n",
        "Download your notebook in .ipynb format and use the following command to convert it to PDF\n",
        "```\n",
        "jupyter nbconvert --to pdf lab4_teamname.ipynb\n",
        "```\n",
        "If you're using Anaconda for package management, you can install `nbconvert` with\n",
        "```\n",
        "conda install -c anaconda nbconvert\n",
        "```\n",
        "Upload your .pdf file to Gradescope.\n",
        "\n",
        "**Only one submission per team!**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "108bf087491648cd81e110c8f58c8c69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17b83db809c54d4eb0d0496a4b0734fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a67d351db63442db8024a0a13680b7b",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79e30295dd2b4a8a8558a919cb83e0ce",
            "value": 100
          }
        },
        "207e63074bb2407591840ac7a1905a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b18e1ccdaa747a78b4ea19fbd9771a1",
              "IPY_MODEL_ab8b8848834e40878356c25898fb4f79",
              "IPY_MODEL_6eb77ec2f2124403a1cf0c0e383a0da4"
            ],
            "layout": "IPY_MODEL_951f53f87c1e4a75b6de2b67c0619e9d"
          }
        },
        "28df8a7d42a94da48fdee6d330b0f7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed0c6842df2d4ae78f1bf99c0351c1f7",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85627365d0d04505b7f5db266fb10856",
            "value": 100
          }
        },
        "312347177b0249aa8fbe0366385d6658": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "389787c5e18642929573351d2def2252": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47cfa8f0a172427a82ace691bcd255b0",
              "IPY_MODEL_17b83db809c54d4eb0d0496a4b0734fe",
              "IPY_MODEL_cbcf22966c714c6f8c4026fa000a7e96"
            ],
            "layout": "IPY_MODEL_871d1504891a42c09086aa35dc34e9b2"
          }
        },
        "39bb3e670e00451e8b3f6e0293efd559": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39d6d8998fd846cab8eb3d1181d9c50f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b88f8dc29a244a8ae4b30ac94cc1396": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c521c0e0f7a47f583c5ba6aeda5492e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40cf2b5e1b344828bb1c79c17f98518d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4471dfe5509a498f9ed63a28a32f0a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_108bf087491648cd81e110c8f58c8c69",
            "placeholder": "​",
            "style": "IPY_MODEL_ffaff15efd0e402c954706b65544377d",
            "value": "Epoch 099 Train 0.0926 Val 0.0830: 100%"
          }
        },
        "470450fee2fd4cbfbb515632711c2822": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47cfa8f0a172427a82ace691bcd255b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9527d3e1a604df7b1734c68aeb79c01",
            "placeholder": "​",
            "style": "IPY_MODEL_79d7ecc6980b4e3ea0359d6fa6cdc4c7",
            "value": "Epoch 099 Train 0.1114 Val 0.0912: 100%"
          }
        },
        "58a95d7eea2b4d9683733e359bbde087": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4b1169b9253457e8c4bfd8b62fc2f95",
            "placeholder": "​",
            "style": "IPY_MODEL_8c7668d2a36647c094bbbbe1d8576f9e",
            "value": "Batch: 100%"
          }
        },
        "592814803c544c39a175c59bf8e19cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79e3be6801cf4c8fb5821e8ea664153d",
              "IPY_MODEL_683bf0756c8f40259cfcbe1f67be953b",
              "IPY_MODEL_fb9ef62a36c24792a3ae2653d5dd214a"
            ],
            "layout": "IPY_MODEL_74a436427ce0499f842b5b4b22e898ba"
          }
        },
        "61a8ed6b241c4b949daf89c251521944": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "683bf0756c8f40259cfcbe1f67be953b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3875ce614724e269a2715a5a6a9a123",
            "max": 287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61a8ed6b241c4b949daf89c251521944",
            "value": 287
          }
        },
        "6a67d351db63442db8024a0a13680b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b98ce79453a4070a924993ca7bdc70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6eb77ec2f2124403a1cf0c0e383a0da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_470450fee2fd4cbfbb515632711c2822",
            "placeholder": "​",
            "style": "IPY_MODEL_7c03892a105940429c08ab086b5bbbc9",
            "value": " 287/287 [00:05&lt;00:00, 55.07it/s]"
          }
        },
        "74a436427ce0499f842b5b4b22e898ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7908b0b0661a4ca593ec68d8c206c32c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79d7ecc6980b4e3ea0359d6fa6cdc4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79e30295dd2b4a8a8558a919cb83e0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79e3be6801cf4c8fb5821e8ea664153d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a144676824dc43a69191034a8623acdf",
            "placeholder": "​",
            "style": "IPY_MODEL_39bb3e670e00451e8b3f6e0293efd559",
            "value": "Batch: 100%"
          }
        },
        "7b18e1ccdaa747a78b4ea19fbd9771a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b88f8dc29a244a8ae4b30ac94cc1396",
            "placeholder": "​",
            "style": "IPY_MODEL_b333a22481684c9299ec595acfc2d096",
            "value": "Batch: 100%"
          }
        },
        "7c03892a105940429c08ab086b5bbbc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "804609d813bd42b8b854b2db57407d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85627365d0d04505b7f5db266fb10856": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87051ac03e9049cdbe8c2fab59a0515e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "871d1504891a42c09086aa35dc34e9b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87c3d51ed95e45fc8f7aa5f41fab7625": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58a95d7eea2b4d9683733e359bbde087",
              "IPY_MODEL_d4c5042b515e4abba1f67650c9342e77",
              "IPY_MODEL_c8bc97a69db94e7f9fe98802817b0b4b"
            ],
            "layout": "IPY_MODEL_87051ac03e9049cdbe8c2fab59a0515e"
          }
        },
        "8c7668d2a36647c094bbbbe1d8576f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9226c1e375b046b3aeb59849ef41c3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "951f53f87c1e4a75b6de2b67c0619e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c579ecfb5048d78b96af1c1d68859c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ca08f8dacfd4775a20abe1354b3a221",
            "placeholder": "​",
            "style": "IPY_MODEL_e1533b201c6b451e98117a6ca54ca0fe",
            "value": " 100/100 [09:35&lt;00:00,  5.75s/it]"
          }
        },
        "9be83304288947fdbed7b94f6779eb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ca08f8dacfd4775a20abe1354b3a221": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a144676824dc43a69191034a8623acdf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3875ce614724e269a2715a5a6a9a123": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b1169b9253457e8c4bfd8b62fc2f95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9527d3e1a604df7b1734c68aeb79c01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9be2e4ce8314b0b8cb56196b1cacc59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab8b8848834e40878356c25898fb4f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e036da5497f740bf9db8ae335d945ae2",
            "max": 287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_312347177b0249aa8fbe0366385d6658",
            "value": 287
          }
        },
        "ae22c15e520f4a149403e9095dbcb8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b005280b25a842ce8a3e1c9306120764": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2aad7bcc7254b26a7951a24add9ea7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f32a4e5559d64966b914fba84305216f",
            "placeholder": "​",
            "style": "IPY_MODEL_ae22c15e520f4a149403e9095dbcb8bf",
            "value": "Epoch 099 Train 0.1132 Val 0.0933: 100%"
          }
        },
        "b333a22481684c9299ec595acfc2d096": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4c5f13ac13a42428cc8e69e54667f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8bc97a69db94e7f9fe98802817b0b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b005280b25a842ce8a3e1c9306120764",
            "placeholder": "​",
            "style": "IPY_MODEL_804609d813bd42b8b854b2db57407d46",
            "value": " 287/287 [00:01&lt;00:00, 273.92it/s]"
          }
        },
        "cbcf22966c714c6f8c4026fa000a7e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d871b7c368ce4975aaff90f036f673ca",
            "placeholder": "​",
            "style": "IPY_MODEL_9226c1e375b046b3aeb59849ef41c3de",
            "value": " 100/100 [02:09&lt;00:00,  1.25s/it]"
          }
        },
        "ce1ddf8a7e03430ea4dbfe22691a8de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4c5042b515e4abba1f67650c9342e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4c5f13ac13a42428cc8e69e54667f1b",
            "max": 287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9be83304288947fdbed7b94f6779eb34",
            "value": 287
          }
        },
        "d871b7c368ce4975aaff90f036f673ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e036da5497f740bf9db8ae335d945ae2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1533b201c6b451e98117a6ca54ca0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eabcf03b26b142d3b849d284caa0955f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f504679020204485b7645c1d2b5f05ab",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b98ce79453a4070a924993ca7bdc70a",
            "value": 100
          }
        },
        "ed0c6842df2d4ae78f1bf99c0351c1f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f32a4e5559d64966b914fba84305216f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f504679020204485b7645c1d2b5f05ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f97e9022073443cfa4d7bead9422d9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4471dfe5509a498f9ed63a28a32f0a25",
              "IPY_MODEL_28df8a7d42a94da48fdee6d330b0f7f2",
              "IPY_MODEL_98c579ecfb5048d78b96af1c1d68859c"
            ],
            "layout": "IPY_MODEL_40cf2b5e1b344828bb1c79c17f98518d"
          }
        },
        "fb5dedd1a4764fc4ad187a4f77dbcaa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2aad7bcc7254b26a7951a24add9ea7b",
              "IPY_MODEL_eabcf03b26b142d3b849d284caa0955f",
              "IPY_MODEL_fd3b5bda042d47edb597c6ea54c90606"
            ],
            "layout": "IPY_MODEL_3c521c0e0f7a47f583c5ba6aeda5492e"
          }
        },
        "fb9ef62a36c24792a3ae2653d5dd214a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9be2e4ce8314b0b8cb56196b1cacc59",
            "placeholder": "​",
            "style": "IPY_MODEL_39d6d8998fd846cab8eb3d1181d9c50f",
            "value": " 287/287 [02:13&lt;00:00, 266.81it/s]"
          }
        },
        "fd3b5bda042d47edb597c6ea54c90606": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7908b0b0661a4ca593ec68d8c206c32c",
            "placeholder": "​",
            "style": "IPY_MODEL_ce1ddf8a7e03430ea4dbfe22691a8de2",
            "value": " 100/100 [04:03&lt;00:00,  1.09s/it]"
          }
        },
        "ffaff15efd0e402c954706b65544377d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
